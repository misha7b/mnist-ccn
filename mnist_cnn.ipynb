{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MNIST dataset\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data.to_numpy().astype(np.float32)\n",
    "y = mnist.target.astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "X /= 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "\n",
    "X_train = X_train.reshape(-1,28, 28, 1)\n",
    "X_test = X_test.reshape(-1,28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title(\"Sample Image from X_train\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 32\n",
      "Learning rate: 0.001\n",
      "Epochs: 10\n",
      "Conv1: 8 filters, 3x3, stride 1, padding 0\n",
      "Pool size: 2\n",
      "FC layer sizes: 128 -> 10\n"
     ]
    }
   ],
   "source": [
    "# general hyperparameters\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# convolutional layer hyperparameters\n",
    "\n",
    "n_filters = 8\n",
    "filter_size = 3\n",
    "stride = 1\n",
    "padding = 0\n",
    "\n",
    "# pooling layer hyperparameters\n",
    "\n",
    "pool_size = 2\n",
    "\n",
    "# fcl hyperparameters\n",
    "\n",
    "fc1_output_size = 128\n",
    "fc2_output_size = 10\n",
    "\n",
    "print(\"Batch size:\", batch_size)\n",
    "print(\"Learning rate:\", learning_rate)\n",
    "print(\"Epochs:\", n_epochs)\n",
    "print(\"Conv1: {} filters, {}x{}, stride {}, padding {}\".format(\n",
    "    n_filters, filter_size, filter_size, stride, padding))\n",
    "print(\"Pool size:\", pool_size)\n",
    "print(\"FC layer sizes:\", fc1_output_size, \"->\", fc2_output_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 28, 28)\n",
      "Output shape: (1, 8, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "class ConvLayer:\n",
    "    def __init__(self, n_filters, filter_size, stride, padding):\n",
    "        \n",
    "        self.n_filters = n_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.stride = stride\n",
    "        self.pad = padding\n",
    "        \n",
    "        # initialize filters\n",
    "        self.filters = np.random.randn(n_filters, filter_size, filter_size) / (filter_size * filter_size)\n",
    "        self.biases = np.zeros((n_filters, 1))\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        Performs a forward pass\n",
    "        '''\n",
    "        \n",
    "        #cache input for the backward pass\n",
    "        self.input = input\n",
    "        batch, depth, height, width = input.shape\n",
    "        \n",
    "        output_width = (width - self.filter_size + 2 * self.pad) // self.stride + 1\n",
    "        output_height = (height - self.filter_size + 2 * self.pad) // self.stride + 1\n",
    "        \n",
    "        output = np.zeros((batch, self.n_filters, output_height, output_width))\n",
    "        \n",
    "        for b in range(batch):\n",
    "            \n",
    "            for f in range(self.n_filters):\n",
    "                \n",
    "                for i in range(output_height):\n",
    "                    \n",
    "                    for j in range(output_width):\n",
    "                        \n",
    "                        region = input[b, :, i:i+self.filter_size, j:j+self.filter_size]\n",
    "                        \n",
    "                        output[b, f, i, j] = np.sum(region * self.filters[f]) + self.b[f]\n",
    "                        \n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, dout, learning_rate):\n",
    "        '''\n",
    "        Performs a backward pass\n",
    "        '''\n",
    "        \n",
    "        batch, depth, height, width = self.input.shape\n",
    "        out_height = height - self.filter_size + 1\n",
    "        out_width = width - self.filter_size + 1\n",
    "        \n",
    "        dfilters = np.zeros(self.filters.shape)\n",
    "        dbiases = np.zeros(self.b.shape)\n",
    "        dinput = np.zeros(self.input.shape)\n",
    "        \n",
    "        for b in range(batch):\n",
    "            \n",
    "            for f in range(self.num_filters):\n",
    "                \n",
    "                for i in range(out_height):\n",
    "                    \n",
    "                    for j in range(out_width):\n",
    "                        \n",
    "                        region = self.input[b, :, i:i+self.filter_size, j:j+self.filter_size]\n",
    "                        dfilters[f] += dout[b, f, i, j] * region\n",
    "                        dbiases[f] += dout[b, f, i, j]\n",
    "                        dinput[b, :, i:i+self.filter_size, j:j+self.filter_size] += dout[b, f, i, j] * self.filters[f]\n",
    "                        \n",
    "        self.filters -= learning_rate * dfilters\n",
    "        self.biases  -= learning_rate * dbiases\n",
    "        \n",
    "        return dinput\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "    \n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        self.input = input\n",
    "        batch, depth, height, width = input.shape\n",
    "        out_height = height // self.pool_size\n",
    "        out_width = width // self.pool_size\n",
    "        \n",
    "        output = np.zeros((batch, depth, out_height, out_width))\n",
    "        self.argmax = np.zeros((batch, depth, out_height, out_width), dtype=int)\n",
    "        \n",
    "        for b in range(batch):\n",
    "            \n",
    "            for d in range(depth):\n",
    "                \n",
    "                for i in range(out_height):\n",
    "                    \n",
    "                    for j in range(out_width):\n",
    "                        \n",
    "                        region = input[b, d, i*self.pool_size:(i+1)*self.pool_size,\n",
    "                                             j*self.pool_size:(j+1)*self.pool_size]\n",
    "                        output[b, d, i, j] = np.max(region)\n",
    "                        self.argmax[b, d, i, j] = np.argmax(region)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        batch, depth, height, width = self.input.shape\n",
    "        dinput = np.zeros_like(self.input)\n",
    "        out_height = height // self.pool_size\n",
    "        out_width  = width // self.pool_size\n",
    "        \n",
    "        for b in range(batch):\n",
    "            for d in range(depth):\n",
    "                for i in range(out_height):\n",
    "                    for j in range(out_width):\n",
    "                        region = self.input[b, d,\n",
    "                                i*self.pool_size:(i+1)*self.pool_size,\n",
    "                                j*self.pool_size:(j+1)*self.pool_size]\n",
    "                        idx = self.argmax[b, d, i, j]\n",
    "                        idx0 = idx // pool_size\n",
    "                        idx1 = idx % pool_size \n",
    "                        dinput[b, d, i*self.pool_size + idx0, j*self.pool_size + idx1] = dout[b, d, i, j]\n",
    "        \n",
    "        return dinput            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer:\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "        \n",
    "        self.weights = np.random.randn(output_size, input_size) / input_size\n",
    "        self.biases = np.zeros((output_size, 1))   \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        self.input = input\n",
    "        return np.dot(self.weights, input) + self.biases\n",
    "    \n",
    "    def backward(self, dout, learning_rate):\n",
    "        \n",
    "        dweights = np.dot(dout, self.input.T)\n",
    "        dbiases = np.sum(dout, axis=1, keepdims=True)\n",
    "        dinput = np.dot(self.weights.T, dout)\n",
    "        \n",
    "        self.weights -= learning_rate * dweights\n",
    "        self.biases  -= learning_rate * dbiases\n",
    "        \n",
    "        return dinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
